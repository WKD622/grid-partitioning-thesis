\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\bibstyle{abbrv}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{polish}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Wstęp}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motywacja}{3}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Fragment symulacji królików i kapusty. Króliki zjadają kapustę zwiększając swoją populację. Ze względu na zwiększoną populację królików i spadającą ilość pożywienia populacja królików spada, z czasem pozwalając populacji kapusty po raz kolejny się odrodzić. Każde okno obsługiwane jest przez osobny rdzeń procesora.\relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{im:kroliki}{{1}{3}{Fragment symulacji królików i kapusty. Króliki zjadają kapustę zwiększając swoją populację. Ze względu na zwiększoną populację królików i spadającą ilość pożywienia populacja królików spada, z czasem pozwalając populacji kapusty po raz kolejny się odrodzić. Każde okno obsługiwane jest przez osobny rdzeń procesora.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Cel pracy}{4}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Struktura pracy}{4}{subsection.1.3}\protected@file@percent }
\citation{metis}
\citation{1364754}
\citation{10.1137/0611030}
\citation{10.5555/147877.147902}
\citation{improved_spectral}
\citation{MiTeThVa93}
\citation{MiTeThVa93}
\citation{10.1137/0611030}
\citation{10.5555/147877.147902}
\citation{improved_spectral}
\citation{fast_multilevel}
\@writefile{toc}{\contentsline {section}{\numberline {2}Istniejące metody partycjonowania grafów}{5}{section.2}\protected@file@percent }
\newlabel{sec:literature}{{2}{5}{Istniejące metody partycjonowania grafów}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Metody spektralne}{5}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Separator wierzchołków d oraz c to \(\{b, e\}\). Źródło: \cite  {MiTeThVa93}.\relax }}{5}{figure.caption.2}\protected@file@percent }
\newlabel{im:separator}{{2}{5}{Separator wierzchołków d oraz c to \(\{b, e\}\). Źródło: \cite {MiTeThVa93}.\relax }{figure.caption.2}{}}
\citation{recursive}
\citation{10.1137/0611030}
\citation{recursive}
\citation{recursive}
\citation{recursive}
\citation{recursive}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Metody rekursywne}{6}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Partycjonowanie rekursywne na głębokości wynoszącej $2$. Linia partycjonowania a-b, która została stworzona przez partycjonowanie poziomu $1$ jest podzielona na $3$ segmenty przez dwie linie partycjonowania poziomu drugiego: c-d, e-f. Źródło: \cite  {recursive}\relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{im:recursive_partitioning}{{3}{6}{Partycjonowanie rekursywne na głębokości wynoszącej $2$. Linia partycjonowania a-b, która została stworzona przez partycjonowanie poziomu $1$ jest podzielona na $3$ segmenty przez dwie linie partycjonowania poziomu drugiego: c-d, e-f. Źródło: \cite {recursive}\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Metoda rekursywna - binarna dekompozycja dla $16$ procesorów. Najpierw tworzone jest wertykalne cięcie, które gwarantuje, że prawy i lewy obszar zawiera połowę pracy do wykonania (lub takie, które jest jak najbliżej takiego podziału). Jeśli dostępne są $4$ procesory to każdy z dwóch segmentów partycjonowany jest horyzontalną linią, która spełnia te same założenia jak ta dla pierwszego wertykalnego cięcia. Procedura jest kontynuowana wykorzystując na zmianę wertykalne i horyzontalne cięcie, aż do otrzymania podziału na oczekiwaną liczbę obszarów. Źródło: \cite  {recursive}\relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{im:rec_partitioning}{{4}{6}{Metoda rekursywna - binarna dekompozycja dla $16$ procesorów. Najpierw tworzone jest wertykalne cięcie, które gwarantuje, że prawy i lewy obszar zawiera połowę pracy do wykonania (lub takie, które jest jak najbliżej takiego podziału). Jeśli dostępne są $4$ procesory to każdy z dwóch segmentów partycjonowany jest horyzontalną linią, która spełnia te same założenia jak ta dla pierwszego wertykalnego cięcia. Procedura jest kontynuowana wykorzystując na zmianę wertykalne i horyzontalne cięcie, aż do otrzymania podziału na oczekiwaną liczbę obszarów. Źródło: \cite {recursive}\relax }{figure.caption.3}{}}
\citation{MiTeThVa93}
\citation{MiTeThVa93}
\citation{Miller1994ACP}
\citation{Raghavan93lineand}
\citation{185417}
\citation{MiTeThVa93}
\citation{NourOmid1987SolvingFE}
\citation{185417}
\citation{MiTeThVa93}
\citation{185417}
\citation{wiki:Graph_embedding}
\citation{MiTeThVa93}
\citation{Chan95geometricspectral}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Metody geometryczne}{7}{subsection.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Rekursywne partycjonowanie mapy USA - pierwszy obrazek od góry - za pomocą algorytmu z artykułu \cite  {MiTeThVa93}. Dwa następne obrazki prezentują rezultat. Dane geometryczne używane są do obliczenia separatorów.\relax }}{7}{figure.caption.4}\protected@file@percent }
\citation{metis}
\citation{jostle}
\citation{Bui1993AHF}
\citation{103500}
\citation{185177}
\citation{279334}
\citation{inproceedings}
\citation{129970}
\citation{10.1145/165939.165942}
\citation{1364754}
\citation{article}
\citation{10.5555/800263.809204}
\citation{metis}
\citation{1364754}
\citation{metis}
\citation{jostle}
\citation{inproceedings}
\citation{inproceedings}
\citation{KARYPIS199896}
\citation{KARYPIS199896}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Metody wielopoziomowe}{8}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Wielopoziomowe partycjonowanie grafu, przedstawiające fazę zmniejszania grafu, następnie przypisanie partycji na zmniejszonym grafie, na końcu przywrócenie grafu do początkowej wielkości. Źródło: \cite  {KARYPIS199896}.\relax }}{8}{figure.caption.5}\protected@file@percent }
\newlabel{im:multilevel_partitioning}{{6}{8}{Wielopoziomowe partycjonowanie grafu, przedstawiające fazę zmniejszania grafu, następnie przypisanie partycji na zmniejszonym grafie, na końcu przywrócenie grafu do początkowej wielkości. Źródło: \cite {KARYPIS199896}.\relax }{figure.caption.5}{}}
\citation{metis}
\citation{jostle}
\citation{Bui1993AHF}
\citation{103500}
\citation{185177}
\citation{279334}
\citation{inproceedings}
\citation{129970}
\citation{10.1145/165939.165942}
\citation{1364754}
\citation{metis}
\citation{jostle}
\citation{inproceedings}
\citation{metis}
\citation{jostle}
\citation{1364754}
\citation{1364754}
\citation{metis}
\citation{jostle}
\citation{1364754}
\citation{1364754}
\citation{Analysis}
\citation{Bui1993AHF}
\citation{1364754}
\citation{weighted_maching}
\citation{KARYPIS199871}
\citation{10.5555/800263.809204}
\citation{6771089}
\citation{6771089}
\citation{10.5555/800263.809204}
\citation{10.1007/3-540-54345-7_64}
\citation{MONIEN2006475}
\citation{10.1007/3-540-44842-X_6}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Porównanie istniejących metod wielopoziomowych}{9}{subsection.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Partycjonowanie siatki 100x100 na 16 obszarów. Od lewej - pmetis \cite  {metis} uzyskuje edge-cut wynoszący 688, następnie Jostle \cite  {jostle} z wynikiem 695 oraz Party \cite  {1364754} z wynikiem 615. Źródło: \cite  {1364754}.\relax }}{9}{figure.caption.6}\protected@file@percent }
\newlabel{im:partitioning_results}{{7}{9}{Partycjonowanie siatki 100x100 na 16 obszarów. Od lewej - pmetis \cite {metis} uzyskuje edge-cut wynoszący 688, następnie Jostle \cite {jostle} z wynikiem 695 oraz Party \cite {1364754} z wynikiem 615. Źródło: \cite {1364754}.\relax }{figure.caption.6}{}}
\citation{1364754}
\citation{weighted_maching}
\citation{10.1007/3-540-44842-X_6}
\citation{weighted_maching}
\@writefile{toc}{\contentsline {section}{\numberline {3}Opis algorytmu}{11}{section.3}\protected@file@percent }
\citation{1364754}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Podział siatki na $m \cdot k$ obszarów}{12}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Konwersja pliku graficznego na graf i redukcja obszarów niepodzielnych}{12}{subsubsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Obrazek, który reprezentuje strukturę siatki do podziału. Żółte obszary to obszary niepodzielne, czerwone to te wyłączone z obliczeń, białe to zwykłe przez które przechodzić będą granice podziału.\relax }}{12}{figure.caption.7}\protected@file@percent }
\newlabel{im:input}{{8}{12}{Obrazek, który reprezentuje strukturę siatki do podziału. Żółte obszary to obszary niepodzielne, czerwone to te wyłączone z obliczeń, białe to zwykłe przez które przechodzić będą granice podziału.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Obrazek (a) przedstawia obrazek wejściowy w rzeczywistym rozmiarze. Obrazki (b) oraz (c) przedstawiają powstały graf. Obrazek (b) przedstawia sposób podejścia do obszarów wyłączonych z obliczeń, gdzie nie tworzone są odwzorowujące je wierzchołki, obrazek (c) pokazuje podejście gdzie w ich miejsce tworzone są wierzchołki z wagą $0$. Dla czytelności wierzchołki zwykłe zostały oznaczone kolorem szarym. \relax }}{13}{figure.caption.8}\protected@file@percent }
\newlabel{im:input2}{{9}{13}{Obrazek (a) przedstawia obrazek wejściowy w rzeczywistym rozmiarze. Obrazki (b) oraz (c) przedstawiają powstały graf. Obrazek (b) przedstawia sposób podejścia do obszarów wyłączonych z obliczeń, gdzie nie tworzone są odwzorowujące je wierzchołki, obrazek (c) pokazuje podejście gdzie w ich miejsce tworzone są wierzchołki z wagą $0$. Dla czytelności wierzchołki zwykłe zostały oznaczone kolorem szarym. \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Obrazek (a) to wejściowa siatka. Obszary niepodzielne są żółte, natomiast wyłączone z obliczeń czerwone. Obrazki (b) oraz (d) pokazują siatkę tuż po konwersji na graf na dwa sposoby. Sposób (b) nadaje wierzchołkom na obszarach wyłączonych z obliczeń wagę $0$, natomiast sposób (d) usuwa wierzchołki obszarów wyłączonych z obliczeń. Na wierzchołkach zaznaczona jest waga. Można zaobserwować wagę $1$ dla wierzchołków zwykłych i tych budujących obszary niepodzielne. Na tym etapie wszystkie krawędzie mają wagę $1$. Obrazek (c) oraz (e) przedstawiają ten sam graf po redukcji obszarów niepodzielnych, odpowiednio z kroku (b) oraz (d). Wierzchołek, do którego został zredukowany obszar niepodzielny otrzymuje powiększoną wagę, równą sumie wag wierzchołków, które redukuje. Każda krawędź, która zastąpiła dwie krawędzie, zyskuje sumę wag tych krawędzi równą $2$.\relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{im:indivisible}{{10}{14}{Obrazek (a) to wejściowa siatka. Obszary niepodzielne są żółte, natomiast wyłączone z obliczeń czerwone. Obrazki (b) oraz (d) pokazują siatkę tuż po konwersji na graf na dwa sposoby. Sposób (b) nadaje wierzchołkom na obszarach wyłączonych z obliczeń wagę $0$, natomiast sposób (d) usuwa wierzchołki obszarów wyłączonych z obliczeń. Na wierzchołkach zaznaczona jest waga. Można zaobserwować wagę $1$ dla wierzchołków zwykłych i tych budujących obszary niepodzielne. Na tym etapie wszystkie krawędzie mają wagę $1$. Obrazek (c) oraz (e) przedstawiają ten sam graf po redukcji obszarów niepodzielnych, odpowiednio z kroku (b) oraz (d). Wierzchołek, do którego został zredukowany obszar niepodzielny otrzymuje powiększoną wagę, równą sumie wag wierzchołków, które redukuje. Każda krawędź, która zastąpiła dwie krawędzie, zyskuje sumę wag tych krawędzi równą $2$.\relax }{figure.caption.9}{}}
\citation{wiki:skojarzenie}
\citation{wiki:skojarzenie}
\citation{wiki:skojarzenie}
\citation{weighted_maching}
\citation{weighted_maching}
\citation{weighted_maching}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Zmniejszanie i partycjonowanie grafu za pomocą algorytmu LAM}{15}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Skojarzenie największe, którego liczba krawędzi wynosi 4. Źródło: \cite  {wiki:skojarzenie}.\relax }}{15}{figure.caption.10}\protected@file@percent }
\newlabel{im:max_skojarzenie}{{11}{15}{Skojarzenie największe, którego liczba krawędzi wynosi 4. Źródło: \cite {wiki:skojarzenie}.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Fragment przebiegu algorytmu LAM. Startując od wybranej arbitralnie krawędzi numer $1$, ścieżka buduje się przez krawędzie z lokalnie wyższymi wagami - krawędź numer $2$ oraz $3$ - aż do znalezienia krawędzi \(\{a, b\}\) z lokalnie największą wagą. (Pokazywane są tylko krawędzie z aktualnego wywołania algorytmu LAM, krawędzi znajdujące się na ścieżce oraz krawędzie sąsiadujące do \(\{a, b\}\). Źródło: \cite  {weighted_maching}.\relax }}{15}{figure.caption.11}\protected@file@percent }
\newlabel{im:lam}{{12}{15}{Fragment przebiegu algorytmu LAM. Startując od wybranej arbitralnie krawędzi numer $1$, ścieżka buduje się przez krawędzie z lokalnie wyższymi wagami - krawędź numer $2$ oraz $3$ - aż do znalezienia krawędzi \(\{a, b\}\) z lokalnie największą wagą. (Pokazywane są tylko krawędzie z aktualnego wywołania algorytmu LAM, krawędzi znajdujące się na ścieżce oraz krawędzie sąsiadujące do \(\{a, b\}\). Źródło: \cite {weighted_maching}.\relax }{figure.caption.11}{}}
\citation{weighted_maching}
\citation{weighted_maching}
\@writefile{lol}{\contentsline {listing}{\numberline {1}{\ignorespaces Kod przedstawiający ulepszony algorytm LAM. Wprowadzone przeze mnie zmiany dotyczyły warunku skojarzenia wierzchołków oraz końcowych instrukcji warunkowych, które mogły zostać uproszczone z racji na brak potrzeby tworzenia zbioru krawędzi do usunięcia - $R$. Niezmodyfikowany kod algorytmu można znaleźć w artykule \cite  {weighted_maching}.\relax }}{16}{listing.1}\protected@file@percent }
\newlabel{code:lam}{{1}{16}{Kod przedstawiający ulepszony algorytm LAM. Wprowadzone przeze mnie zmiany dotyczyły warunku skojarzenia wierzchołków oraz końcowych instrukcji warunkowych, które mogły zostać uproszczone z racji na brak potrzeby tworzenia zbioru krawędzi do usunięcia - $R$. Niezmodyfikowany kod algorytmu można znaleźć w artykule \cite {weighted_maching}.\relax }{listing.1}{}}
\citation{weighted_maching}
\citation{weighted_maching}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Dwa losowo wybrane partycjonowania siatki $50$x$50$ na $8$ obszarów za pomocą samego algorytmu LAM - bez fazy ulepszania podziału. Granice podziałów nie są optymalne, pola obszarów nie są równe, lecz bliskie bycia równym pod względem wielkości pól partycji, co jest oczekiwaną i dobrą bazą do dalszych operacji. Algorytm ma charakter losowy, co znaczy, że każde wywołanie będzie dawać inny rezultat. Zawsze jednak zachowane będzie dążenie do równych i zwartych obszarów.\relax }}{17}{figure.caption.12}\protected@file@percent }
\newlabel{im:lam2}{{13}{17}{Dwa losowo wybrane partycjonowania siatki $50$x$50$ na $8$ obszarów za pomocą samego algorytmu LAM - bez fazy ulepszania podziału. Granice podziałów nie są optymalne, pola obszarów nie są równe, lecz bliskie bycia równym pod względem wielkości pól partycji, co jest oczekiwaną i dobrą bazą do dalszych operacji. Algorytm ma charakter losowy, co znaczy, że każde wywołanie będzie dawać inny rezultat. Zawsze jednak zachowane będzie dążenie do równych i zwartych obszarów.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Obrazek (b) przedstawia partycjonowanie siatki (a) samym algorytmem LAM. Widoczne jest uwzględnianie obszarów niepodzielnych, które na siatce (a) zaznaczone są jako obszary żółte.\relax }}{18}{figure.caption.13}\protected@file@percent }
\newlabel{im:lam_indivisible}{{14}{18}{Obrazek (b) przedstawia partycjonowanie siatki (a) samym algorytmem LAM. Widoczne jest uwzględnianie obszarów niepodzielnych, które na siatce (a) zaznaczone są jako obszary żółte.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Obrazki przedstawiają wybrane, kolejne kroki algorytmu LAM aż do otrzymaniu podziału siatki $50$x$50$ na $13$ obszarów. Przedstawione zostało co siódme wywołanie algorytmu oraz efekt końcowy. Widoczne jest równomierne łączenie obszarów.\relax }}{19}{figure.caption.14}\protected@file@percent }
\newlabel{im:lam_steps}{{15}{19}{Obrazki przedstawiają wybrane, kolejne kroki algorytmu LAM aż do otrzymaniu podziału siatki $50$x$50$ na $13$ obszarów. Przedstawione zostało co siódme wywołanie algorytmu oraz efekt końcowy. Widoczne jest równomierne łączenie obszarów.\relax }{figure.caption.14}{}}
\citation{weighted_maching}
\citation{weighted_maching}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Szczegóły modyfikacji algorytmu LAM}{20}{subsubsection.3.1.3}\protected@file@percent }
\newlabel{eq:condition1}{{1}{20}{Szczegóły modyfikacji algorytmu LAM}{equation.3.1}{}}
\newlabel{eq:condition2}{{2}{20}{Szczegóły modyfikacji algorytmu LAM}{equation.3.2}{}}
\newlabel{eq:condition3}{{3}{20}{Szczegóły modyfikacji algorytmu LAM}{equation.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Obrazek (a) przedstawia siatkę wejściową, której więcej niż połowę zajmuje oznaczony kolorem żółtym obszar niepodzielny. Obrazek (a), (b) oraz (c) przedstawia partycjonowanie siatki na 8 części wykonane algorytmem LAM bez fazy ulepszania podziału. Obrazek (b) pokazuje partycjonowanie wykonane z użyciem warunku \ref  {eq:condition1} na skojarzenie wierzchołków. Obraz (c) oraz (d) prezentuję partycjonowanie wykonane z użyciem warunku \ref  {eq:condition3}.\relax }}{21}{figure.caption.15}\protected@file@percent }
\newlabel{im:discount}{{16}{21}{Obrazek (a) przedstawia siatkę wejściową, której więcej niż połowę zajmuje oznaczony kolorem żółtym obszar niepodzielny. Obrazek (a), (b) oraz (c) przedstawia partycjonowanie siatki na 8 części wykonane algorytmem LAM bez fazy ulepszania podziału. Obrazek (b) pokazuje partycjonowanie wykonane z użyciem warunku \ref {eq:condition1} na skojarzenie wierzchołków. Obraz (c) oraz (d) prezentuję partycjonowanie wykonane z użyciem warunku \ref {eq:condition3}.\relax }{figure.caption.15}{}}
\citation{10.1007/3-540-44842-X_6}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Przywracanie grafu do początkowego rozmiaru wraz z ulepszeniem podziału}{23}{subsubsection.3.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Obrazek (a) przedstawia partycjonowanie siatki (a) samym algorytmem LAM. Obrazek (b) przedstawia ulepszenie podziału z obrazka (a). Zmniejszona została długość granic oraz wyrównane zostały pola.\relax }}{23}{figure.caption.16}\protected@file@percent }
\newlabel{im:refinement}{{17}{23}{Obrazek (a) przedstawia partycjonowanie siatki (a) samym algorytmem LAM. Obrazek (b) przedstawia ulepszenie podziału z obrazka (a). Zmniejszona została długość granic oraz wyrównane zostały pola.\relax }{figure.caption.16}{}}
\citation{1364754}
\@writefile{lol}{\contentsline {listing}{\numberline {2}{\ignorespaces Algorytm przedstawia główną procedurę optymalizującą długość granic.\relax }}{24}{listing.2}\protected@file@percent }
\newlabel{code:main_impr_procedure}{{2}{24}{Algorytm przedstawia główną procedurę optymalizującą długość granic.\relax }{listing.2}{}}
\citation{article}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.5}Używanie Helpful Sets w celu zmniejszenia długości granic}{26}{subsubsection.3.1.5}\protected@file@percent }
\newlabel{eq:helpful_set2}{{4}{26}{Używanie Helpful Sets w celu zmniejszenia długości granic}{equation.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Zbiory 2-helpful. Na górze każdego z 4 przykładów jest zbiór zewnętrzny (ang. external set). Wyliczanie wartości helpfulness na podstawie wzoru \ref  {eq:helpful_set2}: (a): $3-1+0=2$, (b): $6-8+4=2$, (c): $4-3+1=2$ oraz (d): $6-8+4=2$. Na każdym wierzchołku zaznaczona jest jego wartość helpfuless. Źródło: \cite  {article}.\relax }}{26}{figure.caption.17}\protected@file@percent }
\newlabel{im:helpfulsets:example}{{18}{26}{Zbiory 2-helpful. Na górze każdego z 4 przykładów jest zbiór zewnętrzny (ang. external set). Wyliczanie wartości helpfulness na podstawie wzoru \ref {eq:helpful_set2}: (a): $3-1+0=2$, (b): $6-8+4=2$, (c): $4-3+1=2$ oraz (d): $6-8+4=2$. Na każdym wierzchołku zaznaczona jest jego wartość helpfuless. Źródło: \cite {article}.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Obrazki pokazują początkowy podział, a następnie jedno wywołanie algorytmu Helpful Sets. Rozmiar partycji pozostaje niemal identyczny, zmniejsza się długość granicy.\relax }}{27}{figure.caption.18}\protected@file@percent }
\newlabel{im:balancing}{{19}{27}{Obrazki pokazują początkowy podział, a następnie jedno wywołanie algorytmu Helpful Sets. Rozmiar partycji pozostaje niemal identyczny, zmniejsza się długość granicy.\relax }{figure.caption.18}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {3}{\ignorespaces Kod przedstawiający zmodyfikowany na potrzeby niniejszej pracy algorytm Helpful-Set $2$-partitioning.\relax }}{28}{listing.3}\protected@file@percent }
\newlabel{code:helpful_sets}{{3}{28}{Kod przedstawiający zmodyfikowany na potrzeby niniejszej pracy algorytm Helpful-Set $2$-partitioning.\relax }{listing.3}{}}
\citation{article}
\citation{1364754}
\citation{1364754}
\citation{article}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Obrazki przedstawiają kolejne kroki działania algorytmu Helpful Sets na siatce 50x50 podzielonej na 2 obszary przez algorytm LAM. W pierszym kroku tworzony jest stosunkowo mały zbiór helpful, a w kolejnym kroku odpowiednio mały zbiór balancing. W momencie kiedy to się udaje algorytm zwiększa limit liczby wierzchołków, dlatego kolejne kroki wnoszą więcej zmian. Po 4 cyklach budowania i przenoszenia zbioru helpful oraz zbioru balancing granica między obszarami jest znacząco mniejsza, a wielkość obszarów zachowana. Na potrzeby przykładu balansowanie pól jest wyłączone.\relax }}{30}{figure.caption.19}\protected@file@percent }
\newlabel{im:h_steps}{{20}{30}{Obrazki przedstawiają kolejne kroki działania algorytmu Helpful Sets na siatce 50x50 podzielonej na 2 obszary przez algorytm LAM. W pierszym kroku tworzony jest stosunkowo mały zbiór helpful, a w kolejnym kroku odpowiednio mały zbiór balancing. W momencie kiedy to się udaje algorytm zwiększa limit liczby wierzchołków, dlatego kolejne kroki wnoszą więcej zmian. Po 4 cyklach budowania i przenoszenia zbioru helpful oraz zbioru balancing granica między obszarami jest znacząco mniejsza, a wielkość obszarów zachowana. Na potrzeby przykładu balansowanie pól jest wyłączone.\relax }{figure.caption.19}{}}
\citation{1364754}
\@writefile{lol}{\contentsline {listing}{\numberline {4}{\ignorespaces \relax }}{31}{listing.4}\protected@file@percent }
\newlabel{code:old_min_max}{{4}{31}{\relax }{listing.4}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {5}{\ignorespaces \relax }}{31}{listing.5}\protected@file@percent }
\newlabel{code:new_min_max}{{5}{31}{\relax }{listing.5}{}}
\citation{algorithms222}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.6}Szczegóły budowania zbioru helpful}{33}{subsubsection.3.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Zmiana wartości helpfulness dla sąsiadów. Źródło: \cite  {article}.\relax }}{33}{figure.caption.20}\protected@file@percent }
\newlabel{im:helpfulness_neighbours}{{21}{33}{Zmiana wartości helpfulness dla sąsiadów. Źródło: \cite {article}.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Obrazki przedstawiają jak wygląda zbiór wierzchołków, na bazie którego budowany jest zbiór helpful. Obrazek (a) przedstawia partycjonowanie. Zbiór helpful będzie budowany na niebieskiej partycji. Obrazek (b) przedstawia wszystkie wierzchołki zbioru (a), gdzie kolor oznacza wartość helpful. Skala rozpoczyna się od koloru ciemnoniebieskiego dla wierzchołków z wartością helpfulness wynoszącą $-4$ i przechodzi do czerwonego dla wierzchołków z wartością helpfulness $4$. Widoczna jest większa wartość helpfulness dla wierzchołków przy granicy. Obrazek (c) przedstawia wierzchołki, które brane są pod uwagę przez algorytm. Są one filtrowanie na etapie budowania zbioru, tak by zawsze wybierane były wierzchołki znajdujące się na granicy.\relax }}{34}{figure.caption.21}\protected@file@percent }
\newlabel{im:building_helpfulsets}{{22}{34}{Obrazki przedstawiają jak wygląda zbiór wierzchołków, na bazie którego budowany jest zbiór helpful. Obrazek (a) przedstawia partycjonowanie. Zbiór helpful będzie budowany na niebieskiej partycji. Obrazek (b) przedstawia wszystkie wierzchołki zbioru (a), gdzie kolor oznacza wartość helpful. Skala rozpoczyna się od koloru ciemnoniebieskiego dla wierzchołków z wartością helpfulness wynoszącą $-4$ i przechodzi do czerwonego dla wierzchołków z wartością helpfulness $4$. Widoczna jest większa wartość helpfulness dla wierzchołków przy granicy. Obrazek (c) przedstawia wierzchołki, które brane są pod uwagę przez algorytm. Są one filtrowanie na etapie budowania zbioru, tak by zawsze wybierane były wierzchołki znajdujące się na granicy.\relax }{figure.caption.21}{}}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.7}Szukanie zbioru $k$-helpful gdzie $k \geq limit$}{35}{subsubsection.3.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Szukanie zbioru $k$-helpful poprzez przenoszenie wierzchołków z wartością helpfulness $\geq $ $0$ do zbiorów Help (a). (b) to przenoszenie zbioru $S$ na drugą stronę podziału. Źródło: \cite  {article}.\relax }}{35}{figure.caption.22}\protected@file@percent }
\newlabel{im:building-helpfulsets}{{23}{35}{Szukanie zbioru $k$-helpful poprzez przenoszenie wierzchołków z wartością helpfulness $\geq $ $0$ do zbiorów Help (a). (b) to przenoszenie zbioru $S$ na drugą stronę podziału. Źródło: \cite {article}.\relax }{figure.caption.22}{}}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.8}Szczegóły budowania zbioru balancing}{36}{subsubsection.3.1.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Obrazki przedstawiają fazę pierwszą oraz fazę drugą budowania zbioru balancing. Ten sam przypadek podziału można znaleźć na rysunku \ref  {im:balancing}.\relax }}{36}{figure.caption.23}\protected@file@percent }
\newlabel{im:balancing:details}{{24}{36}{Obrazki przedstawiają fazę pierwszą oraz fazę drugą budowania zbioru balancing. Ten sam przypadek podziału można znaleźć na rysunku \ref {im:balancing}.\relax }{figure.caption.23}{}}
\citation{article}
\citation{article}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Przykłady zbiorów 0-helpful. Źródło: \cite  {article}.\relax }}{37}{figure.caption.24}\protected@file@percent }
\newlabel{im:0-helpful}{{25}{37}{Przykłady zbiorów 0-helpful. Źródło: \cite {article}.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Obrazek przedstawiający fazę 2. Źródło: \cite  {article}.\relax }}{37}{figure.caption.25}\protected@file@percent }
\newlabel{im:phase_2}{{26}{37}{Obrazek przedstawiający fazę 2. Źródło: \cite {article}.\relax }{figure.caption.25}{}}
\citation{article}
\citation{article}
\@writefile{lol}{\contentsline {listing}{\numberline {6}{\ignorespaces Algorytm przedstawiający fazę drugą. Źródło: \cite  {article}.\relax }}{38}{listing.6}\protected@file@percent }
\newlabel{code:phase_2}{{6}{38}{Algorytm przedstawiający fazę drugą. Źródło: \cite {article}.\relax }{listing.6}{}}
\citation{1364754}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.9}Balansowanie rozmiarów obszarów}{40}{subsubsection.3.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Obrazki pokazują działania algorytmu optymalizacji granic oraz balansowania rozmiarów pól. Jak widać, z wywołania na wywołanie, czerwony obszar, który był na początku najmniejszy, stopniowo rośnie odbierając wierzchołki sąsiednim obszarom. $p$ wynosi $0.1$.\relax }}{40}{figure.caption.26}\protected@file@percent }
\newlabel{im:fields_balancing}{{27}{40}{Obrazki pokazują działania algorytmu optymalizacji granic oraz balansowania rozmiarów pól. Jak widać, z wywołania na wywołanie, czerwony obszar, który był na początku najmniejszy, stopniowo rośnie odbierając wierzchołki sąsiednim obszarom. $p$ wynosi $0.1$.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.10}Usuwanie obszarów rozproszonych}{42}{subsubsection.3.1.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Na rysunku (a) widać, że niebieski obszar jest w dwóch miejscach - na dole oraz w postaci bardzo małego obszaru na środku. Ten sam efekt występuje dla obszaru zielonego na obrazku (b).\relax }}{42}{figure.caption.27}\protected@file@percent }
\newlabel{im:noises}{{28}{42}{Na rysunku (a) widać, że niebieski obszar jest w dwóch miejscach - na dole oraz w postaci bardzo małego obszaru na środku. Ten sam efekt występuje dla obszaru zielonego na obrazku (b).\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Na rysunku widać obraz siatki podatnej na pojawienie się obszarów rozproszonych. Czerwoną kropką zaznaczony jest obszar podatny na podzielenie na dwie części.\relax }}{42}{figure.caption.28}\protected@file@percent }
\newlabel{im:noises_2}{{29}{42}{Na rysunku widać obraz siatki podatnej na pojawienie się obszarów rozproszonych. Czerwoną kropką zaznaczony jest obszar podatny na podzielenie na dwie części.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Podział siatki na $m$ obszarów}{44}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Obrazek (a) podział na $m \cdot k$ obszarów. Obrazek (b) przedstawia podział $m \cdot k$ obszarów na $m$ obszarów po $k$ podobszarów. $m=4$ oraz $k=4$.\relax }}{44}{figure.caption.29}\protected@file@percent }
\newlabel{im:k_m}{{30}{44}{Obrazek (a) podział na $m \cdot k$ obszarów. Obrazek (b) przedstawia podział $m \cdot k$ obszarów na $m$ obszarów po $k$ podobszarów. $m=4$ oraz $k=4$.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Obrazek (a) podział na $m \cdot k$ obszarów. Obrazek (b) przedstawia podział $m \cdot k$ obszarów na $m$ obszarów po $k$ podobszarów. $m=4$ oraz $k=4$.\relax }}{45}{figure.caption.30}\protected@file@percent }
\newlabel{im:k_m2}{{31}{45}{Obrazek (a) podział na $m \cdot k$ obszarów. Obrazek (b) przedstawia podział $m \cdot k$ obszarów na $m$ obszarów po $k$ podobszarów. $m=4$ oraz $k=4$.\relax }{figure.caption.30}{}}
\citation{1364754}
\citation{1364754}
\citation{1364754}
\citation{1364754}
\citation{1364754}
\citation{1364754}
\citation{1364754}
\@writefile{toc}{\contentsline {section}{\numberline {4}Wyniki}{46}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Wyniki dla podziału na $m \cdot k$ obszarów}{46}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Wyniki dla podziału siatek bez obszarów niepodzielnych i wyłączonych z obliczeń}{47}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {32}{\ignorespaces Siatka $100$x$100$. Podział na $16$ partycji. Sumaryczna długość granic dla tego wyniku wynosi $686$. Wybór najlepszego rezultatu wedle kryterium najmniejszej długości granic. Odchylenie standardowe wielkości pól wynosi $0.0779$.\relax }}{47}{figure.caption.31}\protected@file@percent }
\newlabel{result:w1}{{32}{47}{Siatka $100$x$100$. Podział na $16$ partycji. Sumaryczna długość granic dla tego wyniku wynosi $686$. Wybór najlepszego rezultatu wedle kryterium najmniejszej długości granic. Odchylenie standardowe wielkości pól wynosi $0.0779$.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Wyniki dla podziału siatek z obszarami niepodzielnymi i wyłączonymi z obliczeń}{48}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {33}{\ignorespaces Siatka $50$x$50$. Podział na $9$ partycji. Sumaryczna długość granic dla tego wyniku wynosi $402$. Kryterium wyboru najlepszego rezultatu to najmniejsza różnica pomiędzy polem największej i najmniejszej partycji. Odchylenie standardowe wielkości pól wynosi $0.875$.\relax }}{48}{figure.caption.32}\protected@file@percent }
\newlabel{result:2}{{33}{48}{Siatka $50$x$50$. Podział na $9$ partycji. Sumaryczna długość granic dla tego wyniku wynosi $402$. Kryterium wyboru najlepszego rezultatu to najmniejsza różnica pomiędzy polem największej i najmniejszej partycji. Odchylenie standardowe wielkości pól wynosi $0.875$.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {34}{\ignorespaces Siatka $50$x$50$. Podział na $8$ partycji. Sumaryczna długość granic dla tego wyniku wynosi $313$. Kryterium wyboru najlepszego rezultatu to najmniejsze odchylenie standardowe dla pól partycji. Odchylenie standardowe wielkości pól wynosi $0.1011$.\relax }}{49}{figure.caption.33}\protected@file@percent }
\newlabel{result:3}{{34}{49}{Siatka $50$x$50$. Podział na $8$ partycji. Sumaryczna długość granic dla tego wyniku wynosi $313$. Kryterium wyboru najlepszego rezultatu to najmniejsze odchylenie standardowe dla pól partycji. Odchylenie standardowe wielkości pól wynosi $0.1011$.\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {35}{\ignorespaces Siatka $50$x$50$. Podział na $8$ partycji. Obszary wyłączone z obliczeń mapowane na wierzchołki z wagą $0$. Sumaryczna długość granic dla tego wyniku wynosi $177$. Wybór najlepszego rezultatu wedle kryterium najmniejszej długości granic. Odchylenie standardowe wielkości pól