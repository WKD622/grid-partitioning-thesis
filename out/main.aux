\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\bibstyle{abbrv}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{metis}
\citation{1364754}
\citation{10.1137/0611030}
\citation{10.5555/147877.147902}
\citation{improved_spectral}
\citation{MiTeThVa93}
\citation{MiTeThVa93}
\citation{10.1137/0611030}
\citation{10.5555/147877.147902}
\citation{improved_spectral}
\citation{fast_multilevel}
\citation{recursive}
\citation{10.1137/0611030}
\babel@aux{polish}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Istniejące metody partycjonowania grafów}{1}{section.1}\protected@file@percent }
\newlabel{sec:literature}{{1}{1}{Istniejące metody partycjonowania grafów}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Metody spektralne}{1}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Separator wierzchołków d oraz c to \(\{b, e\}\). Źródło: \cite  {MiTeThVa93}.\relax }}{1}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{im:separator}{{1}{1}{Separator wierzchołków d oraz c to \(\{b, e\}\). Źródło: \cite {MiTeThVa93}.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Metody rekursywne}{1}{subsection.1.2}\protected@file@percent }
\citation{recursive}
\citation{recursive}
\citation{recursive}
\citation{recursive}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Przedstawia partycjonowanie rekursywne na głębokości wynoszącej 2. Linia partycjonowania a-b, która została stworzona przez partycjonowanie poziomu 1 jest podzielona na 3 segmenty przez dwie linie partycjonowania poziomu drugiego: c-d, e-f. Źródło: \cite  {recursive}\relax }}{2}{figure.caption.2}\protected@file@percent }
\newlabel{im:recursive_partitioning}{{2}{2}{Przedstawia partycjonowanie rekursywne na głębokości wynoszącej 2. Linia partycjonowania a-b, która została stworzona przez partycjonowanie poziomu 1 jest podzielona na 3 segmenty przez dwie linie partycjonowania poziomu drugiego: c-d, e-f. Źródło: \cite {recursive}\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Metoda rekursywna - binarna dekompozycja dla 16 procesorów. Najpierw tworzone jest wertykalne cięcie, które gwarantuje, że prawy i lewy obszar zawiera połowę pracy do wykonania (lub takie, które jest jak najbliżej takiego podziału). Jeśli dostępne są 4 procesory to każdy z dwóch segmentów partycjonowany jest horyzontalną linią, która spełnia te same założenia jak ta dla pierwszego wertykalnego cięcia. Procedura jest kontynuowana na zmianę wykorzystując wertykalne i horyzontalne cięcie aż do otrzymania podziału na oczekiwaną liczbę obszarów. Źródło: \cite  {recursive}\relax }}{2}{figure.caption.2}\protected@file@percent }
\newlabel{im:rec_partitioning}{{3}{2}{Metoda rekursywna - binarna dekompozycja dla 16 procesorów. Najpierw tworzone jest wertykalne cięcie, które gwarantuje, że prawy i lewy obszar zawiera połowę pracy do wykonania (lub takie, które jest jak najbliżej takiego podziału). Jeśli dostępne są 4 procesory to każdy z dwóch segmentów partycjonowany jest horyzontalną linią, która spełnia te same założenia jak ta dla pierwszego wertykalnego cięcia. Procedura jest kontynuowana na zmianę wykorzystując wertykalne i horyzontalne cięcie aż do otrzymania podziału na oczekiwaną liczbę obszarów. Źródło: \cite {recursive}\relax }{figure.caption.2}{}}
\citation{MiTeThVa93}
\citation{MiTeThVa93}
\citation{Miller1994ACP}
\citation{Raghavan93lineand}
\citation{185417}
\citation{MiTeThVa93}
\citation{NourOmid1987SolvingFE}
\citation{185417}
\citation{MiTeThVa93}
\citation{185417}
\citation{wiki:Graph_embedding}
\citation{MiTeThVa93}
\citation{Chan95geometricspectral}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Metody geometryczne}{3}{subsection.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Rekursywne partycjonowanie mapy USA - pierwszy obrazek od góry - za pomocą algorytmu z artykułu \cite  {MiTeThVa93}. Dwa następne obrazki prezentują rezultat. Dane geometryczne używane są do obliczenia separatorów.\relax }}{3}{figure.caption.3}\protected@file@percent }
\citation{metis}
\citation{jostle}
\citation{Bui1993AHF}
\citation{103500}
\citation{185177}
\citation{279334}
\citation{inproceedings}
\citation{129970}
\citation{10.1145/165939.165942}
\citation{1364754}
\citation{article}
\citation{10.5555/800263.809204}
\citation{metis}
\citation{1364754}
\citation{metis}
\citation{jostle}
\citation{inproceedings}
\citation{inproceedings}
\citation{KARYPIS199896}
\citation{KARYPIS199896}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Metody wielopoziomowe}{4}{subsection.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Wielopoziomowe partycjonowanie grafu przedstawiające fazę zmniejszania grafu, następnie przypisanie partycji na zmniejszonym grafie, na końcu przywrócenie grafu do początkowej wielkości. Źródło: \cite  {KARYPIS199896}.\relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{im:multilevel_partitioning}{{5}{4}{Wielopoziomowe partycjonowanie grafu przedstawiające fazę zmniejszania grafu, następnie przypisanie partycji na zmniejszonym grafie, na końcu przywrócenie grafu do początkowej wielkości. Źródło: \cite {KARYPIS199896}.\relax }{figure.caption.4}{}}
\citation{metis}
\citation{jostle}
\citation{Bui1993AHF}
\citation{103500}
\citation{185177}
\citation{279334}
\citation{inproceedings}
\citation{129970}
\citation{10.1145/165939.165942}
\citation{1364754}
\citation{metis}
\citation{jostle}
\citation{inproceedings}
\citation{metis}
\citation{jostle}
\citation{1364754}
\citation{1364754}
\citation{metis}
\citation{jostle}
\citation{1364754}
\citation{1364754}
\citation{Analysis}
\citation{Bui1993AHF}
\citation{1364754}
\citation{weighted_maching}
\citation{KARYPIS199871}
\citation{10.5555/800263.809204}
\citation{6771089}
\citation{6771089}
\citation{10.5555/800263.809204}
\citation{10.1007/3-540-54345-7_64}
\citation{MONIEN2006475}
\citation{10.1007/3-540-44842-X_6}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Porównanie istniejących metod wielopoziomowych}{5}{subsection.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Partycjonowanie siatki 100x100 na 16 obszarów. Od lewej - pmetis \cite  {metis} uzyskuje edge-cut wynoszący 688, następnie Jostle \cite  {jostle} z wynikiem 695 oraz Party \cite  {1364754} z wynikiem 615. Źródło: \cite  {1364754}.\relax }}{5}{figure.caption.5}\protected@file@percent }
\newlabel{im:partitioning_results}{{6}{5}{Partycjonowanie siatki 100x100 na 16 obszarów. Od lewej - pmetis \cite {metis} uzyskuje edge-cut wynoszący 688, następnie Jostle \cite {jostle} z wynikiem 695 oraz Party \cite {1364754} z wynikiem 615. Źródło: \cite {1364754}.\relax }{figure.caption.5}{}}
\citation{1364754}
\citation{weighted_maching}
\citation{10.1007/3-540-44842-X_6}
\citation{weighted_maching}
\@writefile{toc}{\contentsline {section}{\numberline {2}Opis algorytmu}{7}{section.2}\protected@file@percent }
\citation{1364754}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Podział siatki na $m \cdot k$ obszarów}{8}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Konwersja pliku graficznego na graf i redukcja obszarów niepodzielnych}{8}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Obrazek, który reprezentuje strukturę siatki do podziału. Żółte obszary to obszary niepodzielne, czerwone to te wyłączone z obliczeń, białe to zwykłe przez które przechodzić będą granice podziału.\relax }}{8}{figure.caption.6}\protected@file@percent }
\newlabel{im:input}{{7}{8}{Obrazek, który reprezentuje strukturę siatki do podziału. Żółte obszary to obszary niepodzielne, czerwone to te wyłączone z obliczeń, białe to zwykłe przez które przechodzić będą granice podziału.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Obrazek (a) pokazuje graf tuż po konwersji z pliku graficznego. Na wierzchołkach zaznaczona jest waga. Obszary niepodzielne są żółte, natomiast wyłączona z obliczeń czerwone. Można zaobserwować wagę $0$ dla wierzchołków wyłączonych z obliczeń oraz wagę $1$ dla wszystkich pozostałych wierzchołków. Na tym etapie wszystkie krawędzie mają wagę $1$. Obrazek (b) przedstawia ten sam graf po redukcji obszarów niepodzielnych. Wierzchołek, do którego został zredukowany otrzymuje powiększoną wagę, równą sumie wag wierzchołków, które redukuje. Niektóre krawędzie, które zastąpiły dwie krawędzie, zyskują sumę wag tych krawędzi równą $2$.\relax }}{9}{figure.caption.7}\protected@file@percent }
\newlabel{im:indivisible}{{8}{9}{Obrazek (a) pokazuje graf tuż po konwersji z pliku graficznego. Na wierzchołkach zaznaczona jest waga. Obszary niepodzielne są żółte, natomiast wyłączona z obliczeń czerwone. Można zaobserwować wagę $0$ dla wierzchołków wyłączonych z obliczeń oraz wagę $1$ dla wszystkich pozostałych wierzchołków. Na tym etapie wszystkie krawędzie mają wagę $1$. Obrazek (b) przedstawia ten sam graf po redukcji obszarów niepodzielnych. Wierzchołek, do którego został zredukowany otrzymuje powiększoną wagę, równą sumie wag wierzchołków, które redukuje. Niektóre krawędzie, które zastąpiły dwie krawędzie, zyskują sumę wag tych krawędzi równą $2$.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Obrazek (a) przedstawia obrazek wejściowy w rzeczywistym rozmiarze. Obrazek (b) przedstawia powstały graf. Dla czytelności wierzchołki zwykłe zostały oznaczone kolorem szarym. \relax }}{9}{figure.caption.8}\protected@file@percent }
\newlabel{im:input2}{{9}{9}{Obrazek (a) przedstawia obrazek wejściowy w rzeczywistym rozmiarze. Obrazek (b) przedstawia powstały graf. Dla czytelności wierzchołki zwykłe zostały oznaczone kolorem szarym. \relax }{figure.caption.8}{}}
\citation{wiki:skojarzenie}
\citation{wiki:skojarzenie}
\citation{wiki:skojarzenie}
\citation{weighted_maching}
\citation{weighted_maching}
\citation{weighted_maching}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Zmniejszanie i partycjonowanie grafu za pomocą algorytmu LAM}{11}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Skojarzenie największe, którego liczba krawędzi wynosi 4. Źródło: \cite  {wiki:skojarzenie}.\relax }}{11}{figure.caption.9}\protected@file@percent }
\newlabel{im:max_skojarzenie}{{10}{11}{Skojarzenie największe, którego liczba krawędzi wynosi 4. Źródło: \cite {wiki:skojarzenie}.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Fragment przebiegu algorytmu LAM. Startując z wybranej arbitralnie krawędzi numer 1, ścieżka buduje się przez krawędzie z lokalnie wyższymi wagami - krawędź numer 2 oraz 3 - aż do znalezienia krawędzi \(\{a, b\}\) z lokalnie największą wagą. (Pokazywane są tylko krawędzie z aktualnego wywołania algorytmu LAM, krawędzi znajdujące się na ścieżce oraz krawędzi sąsiadujące do \(\{a, b\}\). Źródło: \cite  {weighted_maching}.\relax }}{11}{figure.caption.10}\protected@file@percent }
\newlabel{im:lam}{{11}{11}{Fragment przebiegu algorytmu LAM. Startując z wybranej arbitralnie krawędzi numer 1, ścieżka buduje się przez krawędzie z lokalnie wyższymi wagami - krawędź numer 2 oraz 3 - aż do znalezienia krawędzi \(\{a, b\}\) z lokalnie największą wagą. (Pokazywane są tylko krawędzie z aktualnego wywołania algorytmu LAM, krawędzi znajdujące się na ścieżce oraz krawędzi sąsiadujące do \(\{a, b\}\). Źródło: \cite {weighted_maching}.\relax }{figure.caption.10}{}}
\citation{weighted_maching}
\citation{weighted_maching}
\@writefile{lol}{\contentsline {listing}{\numberline {1}{\ignorespaces Pseudokod przedstawiający ulepszony algorytm LAM. Wprowadzone przeze mnie zmiany dotyczyły warunku skojarzenia wierzchołków oraz końcowych instrukcji warunkowych, które mogły zostać uproszczone z racji na brak potrzeby tworzenia zbioru krawędzi do usunięcia - $R$. Niezmodyfikowany pseudokod można znaleźć w artykule \cite  {weighted_maching}.\relax }}{12}{listing.1}\protected@file@percent }
\newlabel{code:lam}{{1}{12}{Pseudokod przedstawiający ulepszony algorytm LAM. Wprowadzone przeze mnie zmiany dotyczyły warunku skojarzenia wierzchołków oraz końcowych instrukcji warunkowych, które mogły zostać uproszczone z racji na brak potrzeby tworzenia zbioru krawędzi do usunięcia - $R$. Niezmodyfikowany pseudokod można znaleźć w artykule \cite {weighted_maching}.\relax }{listing.1}{}}
\citation{weighted_maching}
\citation{weighted_maching}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Dwa losowo wybrane partycjonowania siatki 50x50 na 8 obszarów za pomocą samego algorytmu LAM - bez fazy ulepszania podziału. Granice podziałów nie są optymalne, pola obszarów nie są równe - podział jest jednak bliski bycia równym w kwestii pól co jest oczekiwaną i dobrą bazą do dalszych operacji. Algorytm ma charakterystykę losową, to znaczy, że każde wywołanie będzie dawać inny rezultat. Zawsze jednak zachowane będzie dążenie do równych i zwartych obszarów.\relax }}{13}{figure.caption.11}\protected@file@percent }
\newlabel{im:lam2}{{12}{13}{Dwa losowo wybrane partycjonowania siatki 50x50 na 8 obszarów za pomocą samego algorytmu LAM - bez fazy ulepszania podziału. Granice podziałów nie są optymalne, pola obszarów nie są równe - podział jest jednak bliski bycia równym w kwestii pól co jest oczekiwaną i dobrą bazą do dalszych operacji. Algorytm ma charakterystykę losową, to znaczy, że każde wywołanie będzie dawać inny rezultat. Zawsze jednak zachowane będzie dążenie do równych i zwartych obszarów.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Obrazek (b) przedstawia partycjonowanie siatki (a) samym algorytmem LAM. Widoczne jest uwzględnianie obszarów niepodzielnych, które na siatce (a) zaznaczone są jako obszary żółte.\relax }}{14}{figure.caption.12}\protected@file@percent }
\newlabel{im:lam_indivisible}{{13}{14}{Obrazek (b) przedstawia partycjonowanie siatki (a) samym algorytmem LAM. Widoczne jest uwzględnianie obszarów niepodzielnych, które na siatce (a) zaznaczone są jako obszary żółte.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Obrazki przedstawiają wybrane, kolejne kroki algorytmu LAM aż do otrzymaniu podziału siatki 50x50 na 13 obszarów. Nie są to wszystkie kroki. Rysowane było co siódme wywołanie algorytmu oraz efekt końcowy. Widoczne jest równomierne łączenie obszarów.\relax }}{15}{figure.caption.13}\protected@file@percent }
\newlabel{im:lam_steps}{{14}{15}{Obrazki przedstawiają wybrane, kolejne kroki algorytmu LAM aż do otrzymaniu podziału siatki 50x50 na 13 obszarów. Nie są to wszystkie kroki. Rysowane było co siódme wywołanie algorytmu oraz efekt końcowy. Widoczne jest równomierne łączenie obszarów.\relax }{figure.caption.13}{}}
\citation{weighted_maching}
\citation{weighted_maching}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Szczegóły modyfikacji algorytmu LAM}{16}{subsubsection.2.1.3}\protected@file@percent }
\newlabel{eq:condition1}{{1}{16}{Szczegóły modyfikacji algorytmu LAM}{equation.2.1}{}}
\newlabel{eq:condition2}{{2}{16}{Szczegóły modyfikacji algorytmu LAM}{equation.2.2}{}}
\newlabel{eq:condition3}{{3}{16}{Szczegóły modyfikacji algorytmu LAM}{equation.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Obrazek (a) przedstawia siatkę wejściową, której więcej niż połowę zajmuje oznaczony kolorem żółtym obszar niepodzielny. Obrazek (a), (b) oraz (c) przedstawia partycjonowanie siatki na 8 części wykonane algorytmem LAM bez fazy ulepszania podziału. Obrazek (b) pokazuje partycjonowanie wykonane z użyciem warunku \ref  {eq:condition1} na skojarzenie wierzchołków. Obraz (c) oraz (d) prezentuję partycjonowanie wykonane z użyciem warunku \ref  {eq:condition3}.\relax }}{17}{figure.caption.14}\protected@file@percent }
\newlabel{im:discount}{{15}{17}{Obrazek (a) przedstawia siatkę wejściową, której więcej niż połowę zajmuje oznaczony kolorem żółtym obszar niepodzielny. Obrazek (a), (b) oraz (c) przedstawia partycjonowanie siatki na 8 części wykonane algorytmem LAM bez fazy ulepszania podziału. Obrazek (b) pokazuje partycjonowanie wykonane z użyciem warunku \ref {eq:condition1} na skojarzenie wierzchołków. Obraz (c) oraz (d) prezentuję partycjonowanie wykonane z użyciem warunku \ref {eq:condition3}.\relax }{figure.caption.14}{}}
\citation{10.1007/3-540-44842-X_6}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Przywracanie grafu do początkowego rozmiaru wraz z ulepszeniem podziału}{19}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Obrazek (a) przedstawia partycjonowanie siatki (a) samym algorytmem LAM. Obrazek (b) przedstawia ulepszenie podziału z obrazka (a). Zmniejszona została długość granic oraz wyrównane zostały pola.\relax }}{19}{figure.caption.15}\protected@file@percent }
\newlabel{im:refinement}{{16}{19}{Obrazek (a) przedstawia partycjonowanie siatki (a) samym algorytmem LAM. Obrazek (b) przedstawia ulepszenie podziału z obrazka (a). Zmniejszona została długość granic oraz wyrównane zostały pola.\relax }{figure.caption.15}{}}
\citation{1364754}
\@writefile{lol}{\contentsline {listing}{\numberline {2}{\ignorespaces Pseudokod przedstawia główną procedure optymalizującą długość granic.\relax }}{20}{listing.2}\protected@file@percent }
\newlabel{code:main_impr_procedure}{{2}{20}{Pseudokod przedstawia główną procedure optymalizującą długość granic.\relax }{listing.2}{}}
\citation{article}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Używanie Helpful Sets w celu zmniejszenia długości granic}{22}{subsubsection.2.1.5}\protected@file@percent }
\newlabel{eq:helpful_set2}{{4}{22}{Używanie Helpful Sets w celu zmniejszenia długości granic}{equation.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Zbiory 2-helpful. Na górze każdego z 4 przykładów jest zbiór zewnętrzny (ang. external set). Wyliczanie wartości helpfulness na podstawie wzoru \ref  {eq:helpful_set2}: (a): $3-1+0=2$, (b): $6-8+4=2$, (c): $4-3+1=2$ oraz (d): $6-8+4=2$. Na każdym wierzchołku zaznaczona jest jego wartość helpfuless. Źródło: \cite  {article}.\relax }}{22}{figure.caption.16}\protected@file@percent }
\newlabel{im:helpfulsets:example}{{17}{22}{Zbiory 2-helpful. Na górze każdego z 4 przykładów jest zbiór zewnętrzny (ang. external set). Wyliczanie wartości helpfulness na podstawie wzoru \ref {eq:helpful_set2}: (a): $3-1+0=2$, (b): $6-8+4=2$, (c): $4-3+1=2$ oraz (d): $6-8+4=2$. Na każdym wierzchołku zaznaczona jest jego wartość helpfuless. Źródło: \cite {article}.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Obrazki pokazują początkowy podział, następnie jedno wywołanie algorytmu Helpful Sets. Rozmiar partycji pozostaje niemal identyczny, zmniejsza się długość granicy.\relax }}{23}{figure.caption.17}\protected@file@percent }
\newlabel{im:balancing}{{18}{23}{Obrazki pokazują początkowy podział, następnie jedno wywołanie algorytmu Helpful Sets. Rozmiar partycji pozostaje niemal identyczny, zmniejsza się długość granicy.\relax }{figure.caption.17}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {3}{\ignorespaces Pseudokod przedstawiający zmodyfikowany przeze mnie algorytm Helpful-Set 2-partitioning.\relax }}{24}{listing.3}\protected@file@percent }
\newlabel{code:helpful_sets}{{3}{24}{Pseudokod przedstawiający zmodyfikowany przeze mnie algorytm Helpful-Set 2-partitioning.\relax }{listing.3}{}}
\citation{article}
\citation{1364754}
\citation{1364754}
\citation{article}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Obrazki przedstawiają kolejne kroki działania algorytmu Helpful Sets na siatce 50x50 podzielonej na 2 obszary przez algorytm LAM. W pierszym kroku tworzony jest stosunkowo mały zbiór helpful, a w kolejnym kroku odpowiednio mały zbiór balancing. W momencie kiedy to się udaje algorytm zwiększa limit liczby wierzchołków, dlatego kolejne kroki wnoszą więcej zmian. Po 4 cyklach budowania i przenoszenia zbioru helpful oraz zbioru balancing granica między obszarami jest znacząco mniejsza, a wielkość obszarów zachowana. Na potrzeby przykładu balansowanie pól jest wyłączone.\relax }}{26}{figure.caption.18}\protected@file@percent }
\newlabel{im:h_steps}{{19}{26}{Obrazki przedstawiają kolejne kroki działania algorytmu Helpful Sets na siatce 50x50 podzielonej na 2 obszary przez algorytm LAM. W pierszym kroku tworzony jest stosunkowo mały zbiór helpful, a w kolejnym kroku odpowiednio mały zbiór balancing. W momencie kiedy to się udaje algorytm zwiększa limit liczby wierzchołków, dlatego kolejne kroki wnoszą więcej zmian. Po 4 cyklach budowania i przenoszenia zbioru helpful oraz zbioru balancing granica między obszarami jest znacząco mniejsza, a wielkość obszarów zachowana. Na potrzeby przykładu balansowanie pól jest wyłączone.\relax }{figure.caption.18}{}}
\citation{1364754}
\@writefile{lol}{\contentsline {listing}{\numberline {4}{\ignorespaces \relax }}{27}{listing.4}\protected@file@percent }
\newlabel{code:old_min_max}{{4}{27}{\relax }{listing.4}{}}
\@writefile{lol}{\contentsline {listing}{\numberline {5}{\ignorespaces \relax }}{27}{listing.5}\protected@file@percent }
\newlabel{code:new_min_max}{{5}{27}{\relax }{listing.5}{}}
\citation{algorithms222}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.6}Szczegóły budowania zbioru helpful}{29}{subsubsection.2.1.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Zmiana wartości helpful dla sąsiadów. Źródło: \cite  {article}.\relax }}{29}{figure.caption.19}\protected@file@percent }
\newlabel{im:helpfulness_neighbours}{{20}{29}{Zmiana wartości helpful dla sąsiadów. Źródło: \cite {article}.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Obrazki przedstawiają jak wygląda zbiór wierzchołków, na bazie którego budowany jest zbiór helpful. Obrazek (a) przedstawia partycjonowanie. Zbiór helpful będzie budowany na niebieskiej partycji. Obrazek (b) przedstawia wszystkie wierzchołki zbioru (a), gdzie kolor oznacza wartość helpful. Skala jest od ciemnego niebieskiego dla wierzchołków z wartością helpfulness wynoszącą $-4$ do czerwonego dla wierzchołków z wartością helpfulness $4$. Widoczna jest większa wartość helpfulness dla wierzchołków przy granicy. Obrazek (c) przedstawia wierzchołki, które brane są pod uwagę przez algorytm. Są one filtrowanie na etapie budowania zbioru, tak by zawsze wybierane były wierzchołki znajdujące się na granicy.\relax }}{30}{figure.caption.20}\protected@file@percent }
\newlabel{im:building_helpfulsets}{{21}{30}{Obrazki przedstawiają jak wygląda zbiór wierzchołków, na bazie którego budowany jest zbiór helpful. Obrazek (a) przedstawia partycjonowanie. Zbiór helpful będzie budowany na niebieskiej partycji. Obrazek (b) przedstawia wszystkie wierzchołki zbioru (a), gdzie kolor oznacza wartość helpful. Skala jest od ciemnego niebieskiego dla wierzchołków z wartością helpfulness wynoszącą $-4$ do czerwonego dla wierzchołków z wartością helpfulness $4$. Widoczna jest większa wartość helpfulness dla wierzchołków przy granicy. Obrazek (c) przedstawia wierzchołki, które brane są pod uwagę przez algorytm. Są one filtrowanie na etapie budowania zbioru, tak by zawsze wybierane były wierzchołki znajdujące się na granicy.\relax }{figure.caption.20}{}}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.7}Szukanie zbioru $k$-helpful gdzie $k \geq limit$}{31}{subsubsection.2.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Szukanie zbioru $k$-helpful poprzez przenoszenie wierzchołków z wartością helpfulness $\geq $ $0$ do zbiorów Help (a). (b) to przenoszenie zbioru $S$ na drugą stronę podziału. Źródło: \cite  {article}.\relax }}{31}{figure.caption.21}\protected@file@percent }
\newlabel{im:building-helpfulsets}{{22}{31}{Szukanie zbioru $k$-helpful poprzez przenoszenie wierzchołków z wartością helpfulness $\geq $ $0$ do zbiorów Help (a). (b) to przenoszenie zbioru $S$ na drugą stronę podziału. Źródło: \cite {article}.\relax }{figure.caption.21}{}}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.8}Szczegóły budowania zbioru balancing}{32}{subsubsection.2.1.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Obrazki przedstawiają fazę pierwszą oraz fazę drugą budowania zbioru balancing. Ten sam przypadek podziału można znaleźć na rysunku \ref  {im:balancing}.\relax }}{32}{figure.caption.22}\protected@file@percent }
\newlabel{im:balancing:details}{{23}{32}{Obrazki przedstawiają fazę pierwszą oraz fazę drugą budowania zbioru balancing. Ten sam przypadek podziału można znaleźć na rysunku \ref {im:balancing}.\relax }{figure.caption.22}{}}
\citation{article}
\citation{article}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Przykłady zbiorów 0-helpful. Źródło: \cite  {article}.\relax }}{33}{figure.caption.23}\protected@file@percent }
\newlabel{im:0-helpful}{{24}{33}{Przykłady zbiorów 0-helpful. Źródło: \cite {article}.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Obrazek przedstawiający fazę 2. Źródło: \cite  {article}.\relax }}{33}{figure.caption.24}\protected@file@percent }
\newlabel{im:phase_2}{{25}{33}{Obrazek przedstawiający fazę 2. Źródło: \cite {article}.\relax }{figure.caption.24}{}}
\citation{article}
\citation{article}
\@writefile{lol}{\contentsline {listing}{\numberline {6}{\ignorespaces Pseudokod przedstawiający fazę drugą. Źródło: \cite  {article}.\relax }}{34}{listing.6}\protected@file@percent }
\newlabel{code:phase_2}{{6}{34}{Pseudokod przedstawiający fazę drugą. Źródło: \cite {article}.\relax }{listing.6}{}}
\citation{1364754}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.9}Balansowanie rozmiarów obszarów}{36}{subsubsection.2.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Obrazki pokazują działania algorytmu optymalizacji granic oraz balansowania rozmiarów pól. Jak widać z wywołania na wywołanie czerwony obszar, który był na początku najmniejszy, stopniowo rośnie odbierając wierzchołki sąsiednim obszarom. $p$ wynosi $0.1$.\relax }}{36}{figure.caption.25}\protected@file@percent }
\newlabel{im:fields_balancing}{{26}{36}{Obrazki pokazują działania algorytmu optymalizacji granic oraz balansowania rozmiarów pól. Jak widać z wywołania na wywołanie czerwony obszar, który był na początku najmniejszy, stopniowo rośnie odbierając wierzchołki sąsiednim obszarom. $p$ wynosi $0.1$.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.10}Usuwanie obszarów rozproszonych}{38}{subsubsection.2.1.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Na rysunku (a) widać, że niebieski obszar jest w dwóch miejscach - na dole oraz w postaci bardzo małego obszaru na środku. Ten sam efekt występuje dla obszaru zielonego na obrazku (b).\relax }}{38}{figure.caption.26}\protected@file@percent }
\newlabel{im:noises}{{27}{38}{Na rysunku (a) widać, że niebieski obszar jest w dwóch miejscach - na dole oraz w postaci bardzo małego obszaru na środku. Ten sam efekt występuje dla obszaru zielonego na obrazku (b).\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Na rysunku widać obraz siatki podatnej na pojawienie się obszarów rozproszonych. Czerwoną kropką zaznaczony jest obszar podatny na podzielenie na dwie części.\relax }}{38}{figure.caption.27}\protected@file@percent }
\newlabel{im:noises_2}{{28}{38}{Na rysunku widać obraz siatki podatnej na pojawienie się obszarów rozproszonych. Czerwoną kropką zaznaczony jest obszar podatny na podzielenie na dwie części.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Podział siatki na $m$ obszarów}{40}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Obrazek (a) podział na $m \cdot k$ obszarów. Obrazek (b) przedstawia podział $m \cdot k$ obszarów na $m$ obszarów po $k$ podobszarów. $m=4$ oraz $k=4$.\relax }}{40}{figure.caption.28}\protected@file@percent }
\newlabel{im:k_m}{{29}{40}{Obrazek (a) podział na $m \cdot k$ obszarów. Obrazek (b) przedstawia podział $m \cdot k$ obszarów na $m$ obszarów po $k$ podobszarów. $m=4$ oraz $k=4$.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Obrazek (a) podział na $m \cdot k$ obszarów. Obrazek (b) przedstawia podział $m \cdot k$ obszarów na $m$ obszarów po $k$ podobszarów. $m=4$ oraz $k=4$.\relax }}{41}{figure.caption.29}\protected@file@percent }
\newlabel{im:k_m2}{{30}{41}{Obrazek (a) podział na $m \cdot k$ obszarów. Obrazek (b) przedstawia podział $m \cdot k$ obszarów na $m$ obszarów po $k$ podobszarów. $m=4$ oraz $k=4$.\relax }{figure.caption.29}{}}
\bibdata{input/main}
\bibcite{fast_multilevel}{1}
\bibcite{recursive}{2}
\bibcite{Bui1993AHF}{3}
\bibcite{Chan95geometricspectral}{4}
\bibcite{103500}{5}
\bibcite{article}{6}
\bibcite{10.5555/800263.809204}{7}
\bibcite{129970}{8}
\bibcite{279334}{9}
\bibcite{185177}{10}
\bibcite{inproceedings}{11}
\bibcite{10.1007/3-540-54345-7_64}{12}
\bibcite{Analysis}{13}
\bibcite{KARYPIS199896}{14}
\bibcite{KARYPIS199871}{15}
\bibcite{metis}{16}
\bibcite{6771089}{17}
\bibcite{improved_spectral}{18}
\bibcite{10.1145/165939.165942}{19}
\bibcite{Miller1994ACP}{20}
\bibcite{185417}{21}
\bibcite{MiTeThVa93}{22}
\bibcite{MONIEN2006475}{23}
\bibcite{1364754}{24}
\bibcite{NourOmid1987SolvingFE}{25}
\bibcite{10.1137/0611030}{26}
\bibcite{10.5555/147877.147902}{27}
\bibcite{weighted_maching}{28}
\bibcite{Raghavan93lineand}{29}
\bibcite{10.1007/3-540-44842-X_6}{30}
\bibcite{algorithms222}{31}
\bibcite{jostle}{32}
\bibcite{wiki:Graph_embedding}{33}
\bibcite{wiki:skojarzenie}{34}
\gdef \@abspage@last{44}
